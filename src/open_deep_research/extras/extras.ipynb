{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b42cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Example usage ===\n",
    "# if __name__ == \"__main__\":\n",
    "#   embed_material()\n",
    "  # client = connect_and_create_collection(COLL_NAME=COLLECTION_NAME, SIZE=VECTOR_SIZE)\n",
    "\n",
    "\n",
    "#   qdrant = QdrantVectorStore(\n",
    "#       client=client,\n",
    "#       collection_name=COLLECTION_NAME,\n",
    "#       embedding=EMBEDDING_MODEL,\n",
    "#       sparse_embedding=sparse_embeddings,\n",
    "#       retrieval_mode=RetrievalMode.HYBRID,\n",
    "#       vector_name=\"dense\",\n",
    "#       sparse_vector_name=\"sparse\",\n",
    "\n",
    "#   )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# query = \"animate object\"\n",
    "# found_docs = qdrant.similarity_search(query)\n",
    "# print(found_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd280730",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def embed_material():\n",
    "#     client = connect_and_create_collection(COLL_NAME=COLLECTION_NAME, SIZE=VECTOR_SIZE)\n",
    "\n",
    "#     qdrant = QdrantVectorStore(\n",
    "#         client=client,\n",
    "#         collection_name=COLLECTION_NAME,\n",
    "#         embedding=EMBEDDING_MODEL,\n",
    "#         sparse_embedding=sparse_embeddings,\n",
    "#         retrieval_mode=RetrievalMode.HYBRID,\n",
    "#         vector_name=\"dense\",\n",
    "#         sparse_vector_name=\"sparse\",\n",
    "#     )\n",
    "\n",
    "#     path = \"src/open_deep_research/mcdc.md\"\n",
    "#     with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         markdown = f.read()\n",
    "\n",
    "#     raw_documents = manual_markdown_chunker_with_headers_skip_empty(markdown, path)\n",
    "#     enriched_documents = []\n",
    "\n",
    "#     print(f\"Total chunks to process: {len(raw_documents)}\\n\")\n",
    "\n",
    "#     for idx, doc in enumerate(raw_documents[:1]):\n",
    "#         chunk_text = doc.page_content\n",
    "#         context_summary = situate_context(chunk_text)  # LLM-generated\n",
    "#         # # Split into two parts: first para is context, second is summary\n",
    "#         context_lines = context_summary.strip().split(\"\\n\", 1)\n",
    "#         context = context_lines[0].strip() if len(context_lines) > 0 else \"\"\n",
    "#         summary = context_lines[1].strip() if len(context_lines) > 1 else \"\"\n",
    "\n",
    "#         print(f\"{context}\\n\\n{summary}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# def embed_material():\n",
    "#     client = connect_and_create_collection(COLL_NAME=COLLECTION_NAME, SIZE=VECTOR_SIZE)\n",
    "\n",
    "\n",
    "#     qdrant = QdrantVectorStore(\n",
    "#         client=client,\n",
    "#         collection_name=COLLECTION_NAME,\n",
    "#         embedding=EMBEDDING_MODEL,\n",
    "#         sparse_embedding=sparse_embeddings,\n",
    "#         retrieval_mode=RetrievalMode.HYBRID,\n",
    "#         vector_name=\"dense\",\n",
    "#         sparse_vector_name=\"sparse\",\n",
    "\n",
    "#     )\n",
    "\n",
    "#     path = \"src/open_deep_research/mcdc.md\"\n",
    "#     with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#         markdown = f.read()\n",
    "\n",
    "#     documents = manual_markdown_chunker_with_headers_skip_empty(markdown, path)\n",
    "#     uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "\n",
    "#     print(len(documents), len(uuids))\n",
    "\n",
    "#     # add_documents_throttled(qdrant, documents, batch_size=10, delay=1.1)\n",
    "#     qdrant.add_documents(documents=documents, ids=uuids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174eee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_documents_throttled(qdrant_store, documents, batch_size=10, delay=1.1):\n",
    "    \"\"\"\n",
    "    Add documents to Qdrant in batches with a delay to avoid rate limit errors.\n",
    "\n",
    "    Args:\n",
    "        qdrant_store: Your QdrantVectorStore instance.\n",
    "        documents: List of Document objects to add.\n",
    "        batch_size: Number of documents to add per batch.\n",
    "        delay: Delay in seconds between batches (set > 1s for safety).\n",
    "    \"\"\"\n",
    "    total = len(documents)\n",
    "    for i in range(0, total, batch_size):\n",
    "        batch = documents[i : i + batch_size]\n",
    "        batch_ids = [str(uuid4()) for _ in batch]\n",
    "        print(f\"Adding batch {i//batch_size + 1} with {len(batch)} docs...\")\n",
    "        qdrant_store.add_documents(documents=batch, ids=batch_ids)\n",
    "        if i + batch_size < total:\n",
    "            print(f\"Sleeping for {delay}s to avoid rate limit...\")\n",
    "            time.sleep(delay)\n",
    "    print(\"All documents added successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74925e76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31b981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210eefd6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
